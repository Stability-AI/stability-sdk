{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GM-nO4oBegPm"
   },
   "source": [
    "# Stability Fine-Tuning REST API - Dev Test\n",
    "\n",
    "Thank you for trying the first external beta of the Stability Fine-Tuning service! Note that this is a **developer beta** - bugs and quality issues with the generated fine-tunes may occur. Please reach out to Stability if this is the case - and share what you've made as well!\n",
    "\n",
    "The code below hits the Stability REST API.  This REST API contract is rather solid, so it's unlikely to see large changes before the production release of fine-tuning.\n",
    "\n",
    "Known issues:\n",
    "\n",
    "* Style fine-tunes may result in overfitting - if this is the case, uncomment the `# weight=1.0` field of `DiffusionFineTune` in the diffusion section and provide a value between -1 and 1. You may need to go as low as 0.2 or 0.1.\n",
    "* We will be exposing test parameters soon - please reach out with examples of datasets that produce overfitting or errors if you have them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T9ma2X7bhH8y"
   },
   "outputs": [],
   "source": [
    "#@title Add your API key\n",
    "import getpass\n",
    "\n",
    "#@markdown > Execute this step and paste your API key in the box that appears. <br/> <br/> Visit https://platform.stability.ai/account/keys to get your API key! <br/> <em>Note: If you are not on the fine-tuning whitelist you will receive an error during training.</em>\n",
    "\n",
    "API_KEY = getpass.getpass('Paste your Stability API Key here and press Enter: ')\n",
    "API_HOST = \"https://preview-api.stability.ai\"\n",
    "\n",
    "engine_id = \"stable-diffusion-xl-1024-v1-0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5LM5SUUOhH8z"
   },
   "outputs": [],
   "source": [
    "#@title Initialize the Fine-Tuning REST API wrapper\n",
    "\n",
    "import io\n",
    "import logging\n",
    "import requests\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import base64\n",
    "from enum import Enum\n",
    "from dataclasses import dataclass, is_dataclass, field, asdict\n",
    "from typing import List, Optional, Any\n",
    "from IPython.display import clear_output\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from zipfile import ZipFile\n",
    "\n",
    "\n",
    "class Printable:\n",
    "    \"\"\" Helper class for printing a class to the console. \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def to_json(obj: Any) -> Any:\n",
    "        if isinstance(obj, Enum):\n",
    "            return obj.value\n",
    "        if is_dataclass(obj):\n",
    "            return asdict(obj)\n",
    "\n",
    "        return obj\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.__class__.__name__}: {json.dumps(self, default=self.to_json, indent=4)}\"\n",
    "\n",
    "\n",
    "class ToDict:\n",
    "    \"\"\" Helper class to simplify converting dataclasses to dicts. \"\"\"\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {k: v for k, v in asdict(self).items() if v is not None}\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class FineTune(Printable):\n",
    "    id: str\n",
    "    user_id: str\n",
    "    name: str\n",
    "    mode: str\n",
    "    engine_id: str\n",
    "    training_set_id: str\n",
    "    status: str\n",
    "    failure_reason: Optional[str] = field(default=None)\n",
    "    duration_seconds: Optional[int] = field(default=None)\n",
    "    object_prompt: Optional[str] = field(default=None)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DiffusionFineTune(Printable, ToDict):\n",
    "    id: str\n",
    "    token: str\n",
    "    weight: Optional[float] = field(default=None)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TextPrompt(Printable, ToDict):\n",
    "    text: str\n",
    "    weight: Optional[float] = field(default=None)\n",
    "\n",
    "\n",
    "class Sampler(Enum):\n",
    "    DDIM = \"DDIM\"\n",
    "    DDPM = \"DDPM\"\n",
    "    K_DPMPP_2M = \"K_DPMPP_2M\"\n",
    "    K_DPMPP_2S_ANCESTRAL = \"K_DPMPP_2S_ANCESTRAL\"\n",
    "    K_DPM_2 = \"K_DPM_2\"\n",
    "    K_DPM_2_ANCESTRAL = \"K_DPM_2_ANCESTRAL\"\n",
    "    K_EULER = \"K_EULER\"\n",
    "    K_EULER_ANCESTRAL = \"K_EULER_ANCESTRAL\"\n",
    "    K_HEUN = \"K_HEUN\"\n",
    "    K_LMS = \"K_LMS\"\n",
    "\n",
    "    @staticmethod\n",
    "    def from_string(val) -> Enum or None:\n",
    "        for sampler in Sampler:\n",
    "            if sampler.value == val:\n",
    "                return sampler\n",
    "        raise Exception(f\"Unknown Sampler: {val}\")\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TextToImageParams(Printable):\n",
    "    fine_tunes: List[DiffusionFineTune]\n",
    "    text_prompts: List[TextPrompt]\n",
    "    samples: int\n",
    "    sampler: Sampler\n",
    "    engine_id: str\n",
    "    steps: int\n",
    "    seed: Optional[int] = field(default=0)\n",
    "    cfg_scale: Optional[int] = field(default=7)\n",
    "    width: Optional[int] = field(default=1024)\n",
    "    height: Optional[int] = field(default=1024)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DiffusionResult:\n",
    "    base64: str\n",
    "    seed: int\n",
    "    finish_reason: str\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"DiffusionResult(base64='too long to print', seed='{self.seed}', finish_reason='{self.finish_reason}')\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainingSetBase(Printable):\n",
    "    id: str\n",
    "    name: str\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainingSetImage(Printable):\n",
    "    id: str\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainingSet(TrainingSetBase):\n",
    "    images: List[TrainingSetImage]\n",
    "\n",
    "\n",
    "class FineTuningRESTWrapper:\n",
    "    \"\"\"\n",
    "    Helper class to simplify interacting with the fine-tuning service via\n",
    "    Stability's REST API.\n",
    "\n",
    "    While this class can be copied to your local environment, it is not likely\n",
    "    robust enough for your needs and does not support all of the features that\n",
    "    the REST API offers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, api_key: str, api_host: str):\n",
    "        self.api_key = api_key\n",
    "        self.api_host = api_host\n",
    "\n",
    "    def create_fine_tune(self,\n",
    "                         name: str,\n",
    "                         images: List[str],\n",
    "                         engine_id: str,\n",
    "                         mode: str,\n",
    "                         object_prompt: Optional[str] = None) -> FineTune:\n",
    "        print(f\"Creating {mode} fine-tune called '{name}' using {len(images)} images...\")\n",
    "\n",
    "        payload = {\"name\": name, \"engine_id\": engine_id, \"mode\": mode}\n",
    "        if object_prompt is not None:\n",
    "            payload[\"object_prompt\"] = object_prompt\n",
    "\n",
    "        # Create a training set\n",
    "        training_set_id = self.create_training_set(name=name)\n",
    "        payload[\"training_set_id\"] = training_set_id\n",
    "        print(f\"\\tCreated training set {training_set_id}\")\n",
    "\n",
    "        # Add images to the training set\n",
    "        for image in images:\n",
    "            print(f\"\\t\\tAdding {os.path.basename(image)}\")\n",
    "            self.add_image_to_training_set(\n",
    "                training_set_id=training_set_id,\n",
    "                image=image\n",
    "            )\n",
    "\n",
    "        # Create the fine-tune\n",
    "        print(f\"\\tCreating a fine-tune from the training set\")\n",
    "        response = requests.post(\n",
    "            f\"{self.api_host}/v1/fine-tunes\",\n",
    "            json=payload,\n",
    "            headers={\n",
    "                \"Authorization\": self.api_key,\n",
    "                \"Content-Type\": \"application/json\"\n",
    "            }\n",
    "        )\n",
    "        raise_on_non200(response)\n",
    "        print(f\"\\tCreated fine-tune {response.json()['id']}\")\n",
    "\n",
    "        print(f\"Success\")\n",
    "        return FineTune(**response.json())\n",
    "\n",
    "    def get_fine_tune(self, fine_tune_id: str) -> FineTune:\n",
    "        response = requests.get(\n",
    "            f\"{self.api_host}/v1/fine-tunes/{fine_tune_id}\",\n",
    "            headers={\"Authorization\": self.api_key}\n",
    "        )\n",
    "\n",
    "        raise_on_non200(response)\n",
    "\n",
    "        return FineTune(**response.json())\n",
    "\n",
    "    def list_fine_tunes(self) -> List[FineTune]:\n",
    "        response = requests.get(\n",
    "            f\"{self.api_host}/v1/fine-tunes\",\n",
    "            headers={\"Authorization\": self.api_key}\n",
    "        )\n",
    "\n",
    "        raise_on_non200(response)\n",
    "\n",
    "        return [FineTune(**ft) for ft in response.json()]\n",
    "\n",
    "    def rename_fine_tune(self, fine_tune_id: str, name: str) -> FineTune:\n",
    "        response = requests.patch(\n",
    "            f\"{self.api_host}/v1/fine-tunes/{fine_tune_id}\",\n",
    "            json={\"operation\": \"RENAME\", \"name\": name},\n",
    "            headers={\n",
    "                \"Authorization\": self.api_key,\n",
    "                \"Content-Type\": \"application/json\"\n",
    "            }\n",
    "        )\n",
    "\n",
    "        raise_on_non200(response)\n",
    "\n",
    "        return FineTune(**response.json())\n",
    "\n",
    "    def retrain_fine_tune(self, fine_tune_id: str) -> FineTune:\n",
    "        response = requests.patch(\n",
    "            f\"{self.api_host}/v1/fine-tunes/{fine_tune_id}\",\n",
    "            json={\"operation\": \"RETRAIN\"},\n",
    "            headers={\n",
    "                \"Authorization\": self.api_key,\n",
    "                \"Content-Type\": \"application/json\"\n",
    "            }\n",
    "        )\n",
    "\n",
    "        raise_on_non200(response)\n",
    "\n",
    "        return FineTune(**response.json())\n",
    "\n",
    "    def delete_fine_tune(self, fine_tune: FineTune):\n",
    "        # Delete the underlying training set\n",
    "        self.delete_training_set(fine_tune.training_set_id)\n",
    "\n",
    "        # Delete the fine-tune\n",
    "        response = requests.delete(\n",
    "            f\"{self.api_host}/v1/fine-tunes/{fine_tune.id}\",\n",
    "            headers={\"Authorization\": self.api_key}\n",
    "        )\n",
    "\n",
    "        raise_on_non200(response)\n",
    "\n",
    "    def create_training_set(self, name: str) -> str:\n",
    "        response = requests.post(\n",
    "            f\"{self.api_host}/v1/training-sets\",\n",
    "            json={\"name\": name},\n",
    "            headers={\n",
    "                \"Authorization\": self.api_key,\n",
    "                \"Content-Type\": \"application/json\"\n",
    "            }\n",
    "        )\n",
    "\n",
    "        raise_on_non200(response)\n",
    "\n",
    "        return response.json().get('id')\n",
    "\n",
    "    def get_training_set(self, training_set_id: str) -> TrainingSet:\n",
    "        response = requests.get(\n",
    "            f\"{self.api_host}/v1/training-sets/{training_set_id}\",\n",
    "            headers={\"Authorization\": self.api_key}\n",
    "        )\n",
    "\n",
    "        raise_on_non200(response)\n",
    "\n",
    "        return TrainingSet(**response.json())\n",
    "\n",
    "    def list_training_sets(self) -> List[TrainingSetBase]:\n",
    "        response = requests.get(\n",
    "            f\"{self.api_host}/v1/training-sets\",\n",
    "            headers={\"Authorization\": self.api_key}\n",
    "        )\n",
    "\n",
    "        raise_on_non200(response)\n",
    "\n",
    "        return [TrainingSetBase(**tsb) for tsb in response.json()]\n",
    "\n",
    "    def add_image_to_training_set(self, training_set_id: str, image: str) -> str:\n",
    "        with open(image, 'rb') as image_file:\n",
    "            response = requests.post(\n",
    "                f\"{self.api_host}/v1/training-sets/{training_set_id}/images\",\n",
    "                headers={\"Authorization\": self.api_key},\n",
    "                files={'image': image_file}\n",
    "            )\n",
    "\n",
    "        raise_on_non200(response)\n",
    "\n",
    "        return response.json().get('id')\n",
    "\n",
    "    def remove_image_from_training_set(self, training_set_id: str, image_id: str) -> None:\n",
    "        response = requests.delete(\n",
    "            f\"{self.api_host}/v1/training-sets/{training_set_id}/images/{image_id}\",\n",
    "            headers={\"Authorization\": self.api_key}\n",
    "        )\n",
    "\n",
    "        raise_on_non200(response)\n",
    "\n",
    "    def delete_training_set(self, training_set_id: str) -> None:\n",
    "        response = requests.delete(\n",
    "            f\"{self.api_host}/v1/training-sets/{training_set_id}\",\n",
    "            headers={\"Authorization\": self.api_key}\n",
    "        )\n",
    "\n",
    "        raise_on_non200(response)\n",
    "\n",
    "    def text_to_image(self, params: TextToImageParams) -> List[DiffusionResult]:\n",
    "        payload = {\n",
    "            \"fine_tunes\": [ft.to_dict() for ft in params.fine_tunes],\n",
    "            \"text_prompts\": [tp.to_dict() for tp in params.text_prompts],\n",
    "            \"samples\": params.samples,\n",
    "            \"sampler\": params.sampler.value,\n",
    "            \"steps\": params.steps,\n",
    "            \"seed\": params.seed,\n",
    "            \"width\": params.width,\n",
    "            \"height\": params.height,\n",
    "            \"cfg_scale\": params.cfg_scale,\n",
    "        }\n",
    "\n",
    "        response = requests.post(\n",
    "            f\"{self.api_host}/v1/generation/{params.engine_id}/text-to-image\",\n",
    "            json=payload,\n",
    "            headers={\n",
    "                \"Authorization\": self.api_key,\n",
    "                \"Accept\": \"application/json\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "        raise_on_non200(response)\n",
    "\n",
    "        return [\n",
    "            DiffusionResult(base64=item[\"base64\"], seed=item[\"seed\"], finish_reason=item[\"finishReason\"])\n",
    "            for item in response.json()[\"artifacts\"]\n",
    "        ]\n",
    "\n",
    "\n",
    "def raise_on_non200(response):\n",
    "    if 200 <= response.status_code < 300:\n",
    "        return\n",
    "    raise Exception(f\"Status code {response.status_code}: {json.dumps(response.json(), indent=4)}\")\n",
    "\n",
    "\n",
    "# Redirect logs to print statements so we can see them in the notebook\n",
    "class PrintHandler(logging.Handler):\n",
    "    def emit(self, record):\n",
    "        print(self.format(record))\n",
    "logging.getLogger().addHandler(PrintHandler())\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "# Initialize the fine-tune service\n",
    "rest_api = FineTuningRESTWrapper(API_KEY, API_HOST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iQL5dFsfhH8z"
   },
   "outputs": [],
   "source": [
    "#@title List fine-tunes for this user / organization.\n",
    "fine_tunes = rest_api.list_fine_tunes()\n",
    "print(f\"Found {len(fine_tunes)} models\")\n",
    "for fine_tune in fine_tunes:\n",
    "    print(f\"  Model {fine_tune.id} {fine_tune.status:<9} {fine_tune.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_gOf0i_gmCd"
   },
   "source": [
    "# Dataset uploading\n",
    "\n",
    "For training, we need a dataset of images in a `.zip` file.\n",
    "\n",
    "<em>Please only upload images that you have the permission to use.</em>\n",
    "\n",
    "\n",
    "### Dataset image dimensions\n",
    "\n",
    "- Images **cannot** have any side less than 328px\n",
    "- Images **cannot** be larger than 10MB\n",
    "\n",
    "There is no upper-bound for what we'll accept for an image's dimensions, but any side above 1024px will be scaled down to 1024px, while preserving aspect ratio. For example:\n",
    "- `3024x4032` will be scaled down to `768x1024`\n",
    "- `1118x1118` will be scaled down to `1024x1024`\n",
    "\n",
    "\n",
    "### Dataset size\n",
    "\n",
    "- Datasets **cannot** have fewer than 3 images\n",
    "- Datasets **cannot** have more than 64 images\n",
    "\n",
    "A larger dataset often tends to result in a more accurate fine-tune, but will also take longer to train.\n",
    "\n",
    "While each mode can accept up to 64 images, we have a few suggestions for a starter dataset based on the mode you are using:\n",
    "*   `FACE`: 6 or more images.\n",
    "*   `OBJECT`: 6 - 10 images.\n",
    "*   `STYLE`: 20 - 30 images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9C1YOFxIhTJp"
   },
   "outputs": [],
   "source": [
    "#@title Upload ZIP file of images\n",
    "training_dir = \"./train\"\n",
    "Path(training_dir).mkdir(exist_ok=True)\n",
    "try:\n",
    "    from google.colab import files\n",
    "\n",
    "    upload_res = files.upload()\n",
    "    print(upload_res.keys())\n",
    "    extracted_dir = list(upload_res.keys())[0]\n",
    "    print(f\"Received {extracted_dir}\")\n",
    "    if not extracted_dir.endswith(\".zip\"):\n",
    "        raise ValueError(\"Uploaded file must be a zip file\")\n",
    "\n",
    "    zf = ZipFile(io.BytesIO(upload_res[extracted_dir]), \"r\")\n",
    "    extracted_dir = Path(extracted_dir).stem\n",
    "    print(f\"Extracting to {extracted_dir}\")\n",
    "    zf.extractall(extracted_dir)\n",
    "\n",
    "    for root, dirs, files in os.walk(extracted_dir):\n",
    "        for file in files:\n",
    "            source_path = os.path.join(root, file)\n",
    "            target_path = os.path.join(training_dir, file)\n",
    "\n",
    "            if 'MACOSX' in source_path or 'DS' in source_path:\n",
    "              continue\n",
    "            print('Copying', source_path, '==>', target_path)\n",
    "            # Move the file to the target directory\n",
    "            shutil.move(source_path, target_path)\n",
    "\n",
    "\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "print(f\"Using training images from: {training_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8xJLYZ4fgoU9"
   },
   "source": [
    "# Let the training begin!\n",
    "\n",
    "Now we're ready to train our fine-tune. Use the parameters below to configure the name and the kind of fine-tune\n",
    "\n",
    "Please note that the training duration will vary based on:\n",
    "- The number of images in your dataset\n",
    "- The `training_mode` used\n",
    "- The `engine_id` that is being fine-tuned on\n",
    "\n",
    "However, the following are some rough estimates for the training duration for each mode based on our recommended dataset sizes:\n",
    "\n",
    "* `FACE`: 4 - 5 minutes.\n",
    "* `OBJECT`: 5 - 10 minutes.\n",
    "* `STYLE`: 20 - 30 minutes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VLyYQVM3hH8z"
   },
   "outputs": [],
   "source": [
    "#@title Create a fine-tune and begin training\n",
    "fine_tune_name = \"my dog spot\" #@param {type:\"string\"}\n",
    "#@markdown > Requirements: <ul><li>Must be unique (only across your account, not globally)</li> <li>Must be between 3 and 64 characters (inclusive)</li> <li>Must only contain letters, numbers, spaces, or hyphens</li></ul>\n",
    "training_mode = \"OBJECT\" #@param [\"FACE\", \"STYLE\", \"OBJECT\"] {type:\"string\"}\n",
    "#@markdown > Determines the kind of fine-tune you're creating: <ul><li><code>FACE</code> - a fine-tune on faces; expects pictures containing a face; automatically crops and centers on the face detected in the input photos.</li> <li> <code>OBJECT</code> - a fine-tune on a particular object (e.g. a bottle); segments out the object using the `object_prompt` below</li> <li><code>STYLE</code> - a fine-tune on a particular style (e.g. satellite photos of earth); crops the images and filters for image quality.</li></ul>\n",
    "object_prompt = \"dog\" #@param {type:\"string\"}\n",
    "#@markdown > Used for segmenting out your subject when the `training_mode` is `OBJECT`.  (i.e. if you want to fine tune on a cat, put `cat` - for a bottle of liquor, use `bottle`. In general, it's best to use the most general word you can to describe your object.)\n",
    "\n",
    "# Gather training images\n",
    "images = []\n",
    "for filename in os.listdir(training_dir):\n",
    "    if os.path.splitext(filename)[1].lower() in ['.png', '.jpg', '.jpeg', '.heic']:\n",
    "        images.append(os.path.join(training_dir, filename))\n",
    "\n",
    "# Create the fine-tune\n",
    "fine_tune = rest_api.create_fine_tune(\n",
    "    name=fine_tune_name,\n",
    "    images=images,\n",
    "    mode=training_mode,\n",
    "    object_prompt=object_prompt if training_mode == \"OBJECT\" else None,\n",
    "    engine_id=engine_id,\n",
    ")\n",
    "\n",
    "print()\n",
    "print(fine_tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yEKyO3-bhH8z"
   },
   "outputs": [],
   "source": [
    "#@title Check on training status\n",
    "start_time = time.time()\n",
    "while fine_tune.status != \"COMPLETED\" and fine_tune.status != \"FAILED\":\n",
    "    fine_tune = rest_api.get_fine_tune(fine_tune.id)\n",
    "    elapsed = time.time() - start_time\n",
    "    clear_output(wait=True)\n",
    "    print(f\"Training '{fine_tune.name}' ({fine_tune.id}) status: {fine_tune.status} for {elapsed:.0f} seconds\")\n",
    "    time.sleep(10)\n",
    "\n",
    "clear_output(wait=True)\n",
    "status_message = \"completed\" if fine_tune.status == \"COMPLETED\" else \"failed\"\n",
    "print(f\"Training '{fine_tune.name}' ({fine_tune.id}) {status_message} after {elapsed:.0f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qr4jBHX7hH8z"
   },
   "outputs": [],
   "source": [
    "#@title If training fails for some reason, you can resubmit the fine-tune\n",
    "if fine_tune.status == \"FAILED\":\n",
    "    print(f\"Training failed, due to {fine_tune.failure_reason}. Retraining...\")\n",
    "    fine_tune = rest_api.retrain_fine_tune(fine_tune.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Ugkjgy2hH8z"
   },
   "outputs": [],
   "source": [
    "#@title <font color=\"#FFFFFF\">Diffuse with your fine-tune(s)\n",
    "\n",
    "prompt_token=\"$my-dog\" #@param {type:\"string\"}\n",
    "#@markdown > Each fine-tune you want to diffuse with must provide a token. This token is a short-hand that allows you to reference your fine-tune directly in the prompt. <br/><br/> For example, if your token was `$my-dog` you might use a prompt like: `a picture of $my-dog` or `$my-dog chasing a rabbit`. <br/><br/> If you have more than one fine-tune you can combine them!  Given some fine-tune of film noir images you could use a prompt like `$my-dog in the style of $film-noir`.\n",
    "prompt=\"a photo of $my-dog\"  #@param {type:\"string\"}\n",
    "#@markdown > The prompt to diffuse with.  Must contain the `prompt_token` at least once.\n",
    "dimensions=\"1024x1024\" #@param ['1024x1024', '1152x896', '1216x832', '1344x768', '1536x640', '640x1536', '768x1344', '832x1216', '896x1152']\n",
    "#@markdown > The dimensions of the image to generate, in pixels, and in the format width x height.\n",
    "samples=1 #@param {type:\"slider\", min:1, max:10, step:1}\n",
    "#@markdown > The number of images to generate. Requesting a large number of images may negatively response time.\n",
    "steps=32 #@param {type:\"slider\", min:30, max:60, step:1}\n",
    "#@markdown > The number of iterations or stages a diffusion model goes through in the process of generating an image from a given text prompt. Lower steps will generate more quickly, but if steps are lowered too much, image quality will suffer. Images with higher steps take longer to generate, but often give more detailed results.\n",
    "cfg_scale=7 #@param {type:\"slider\", min:0, max:35, step:1}\n",
    "#@markdown > CFG (Classifier Free Guidance) scale determines how strictly the diffusion process adheres to the prompt text (higher values keep your image closer to your prompt).\n",
    "seed=42  #@param {type:\"number\"}\n",
    "#@markdown > The noise seed to use during diffusion.  Using `0` means a random seed will be generated for each image.  If you provide a non-zero value, images will be far less random.\n",
    "\n",
    "params = TextToImageParams(\n",
    "    fine_tunes=[\n",
    "        DiffusionFineTune(\n",
    "            id=fine_tune.id,\n",
    "            token=prompt_token,\n",
    "            # Uncomment the following to provide a weight for the fine-tune\n",
    "            # weight=1.0\n",
    "        ),\n",
    "\n",
    "        # Uncomment the following to use multiple fine-tunes at once\n",
    "        # DiffusionFineTune(\n",
    "        #     id=\"\",\n",
    "        #     token=\"\",\n",
    "        #     # weight=1.0\n",
    "        # ),\n",
    "    ],\n",
    "    text_prompts=[\n",
    "        TextPrompt(\n",
    "            text=prompt,\n",
    "            # weight=1.0\n",
    "        ),\n",
    "    ],\n",
    "    engine_id=engine_id,\n",
    "    samples=samples,\n",
    "    steps=steps,\n",
    "    seed=seed,\n",
    "    cfg_scale=cfg_scale,\n",
    "    width=int(dimensions.split(\"x\")[0]),\n",
    "    height=int(dimensions.split(\"x\")[1]),\n",
    "    sampler=Sampler.K_DPMPP_2S_ANCESTRAL\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "images = rest_api.text_to_image(params)\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"Diffusion completed in {elapsed:.0f} seconds!\")\n",
    "print(f\"The {len(images)} results will be displayed below momentarily (depending on the speed of Colab).\\n\")\n",
    "\n",
    "for image in images:\n",
    "  display(Image.open(io.BytesIO(base64.b64decode(image.base64))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3BZLVniihH8z"
   },
   "outputs": [],
   "source": [
    "#@title (Optional) Rename your fine-tune\n",
    "\n",
    "name = \"\" #@param {type:\"string\"}\n",
    "rest_api.rename_fine_tune(fine_tune.id, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eUFTMZOvhH80"
   },
   "outputs": [],
   "source": [
    "#@title (Optional) Delete your fine-tune\n",
    "rest_api.delete_fine_tune(fine_tune)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
